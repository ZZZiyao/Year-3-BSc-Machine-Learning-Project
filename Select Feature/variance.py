import pandas as pd
from sklearn.preprocessing import StandardScaler

# è¯»å–æ•°æ®
data_path = r'D:\Year3\BSc Project\Particle-Machine-Learning\balanced_data.csv'
data = pd.read_csv(data_path)

# è¯»å–ç‰¹å¾é‡è¦æ€§æ–‡ä»¶ï¼Œé€‰æ‹©ç‰¹å¾
selected_features_path = r'D:\Year3\BSc Project\Particle-Machine-Learning\permutation_feature_importance.csv'
selected_features = pd.read_csv(selected_features_path)['Feature'].tolist()
data = data[selected_features]

# å…ˆè¿›è¡Œæ ‡å‡†åŒ–ï¼ˆZ-scoreï¼‰ï¼Œæ¶ˆé™¤å°ºåº¦å½±å“
scaler = StandardScaler()
data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)

# è®¡ç®—æ ‡å‡†åŒ–åçš„æ–¹å·®
feature_variance = data_scaled.var()

# è®¾å®šæ–¹å·®é˜ˆå€¼ï¼Œæ¯”å¦‚ < 0.01 è®¤ä¸ºæ˜¯å°æ–¹å·®
low_variance_features = feature_variance[feature_variance < 0.01]

# æ‰“å°æ–¹å·®å°çš„ç‰¹å¾
print("ğŸ“Š ä½æ–¹å·®ç‰¹å¾ï¼ˆæ–¹å·® < 0.01ï¼‰(æ ‡å‡†åŒ–å)ï¼š")
print(low_variance_features)

# å¯é€‰ï¼šä¿å­˜åˆ° CSV æ–‡ä»¶
low_variance_features.to_csv("low_variance_features_scaled.csv", header=True)

print(f"âœ… ä½æ–¹å·®ç‰¹å¾å·²ä¿å­˜è‡³ 'low_variance_features_scaled.csv'")
